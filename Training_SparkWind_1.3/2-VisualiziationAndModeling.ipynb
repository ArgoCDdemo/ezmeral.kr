{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22a1190-ac9e-4b2f-abaf-d4f984354bd2",
   "metadata": {},
   "source": [
    "# Lab 2 - Visualization and Modeling\n",
    "\n",
    "In this lab we will do some basic data visualization to see what kind of data we are working with\n",
    "Then we will start creating some models\n",
    "\n",
    "Please use <b>https</b> whenever providing your livy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be32b3c-0692-4918-bf49-b4da1768b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use https please \n",
    "%setLivy --url https://mip-bd-vm129.mip.storage.hpecorp.net:10018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425c34a-0966-4fb7-9db3-4c110cc26061",
   "metadata": {},
   "source": [
    "**If you set the Livy magic from current notebook then please restart the kernel and ingore setting up Livy next time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182d60a-e91d-4f6c-8031-8491011567ba",
   "metadata": {},
   "source": [
    "# Overriding default spark configuration using configure magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890e8ea-1f37-493d-8ea7-7a238c480ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f \n",
    "{ \n",
    "    \"conf\":{ \n",
    "        \"spark.ssl.enabled\" : false, \n",
    "        \"spark.hadoop.fs.dtap.impl\" : \"com.bluedata.hadoop.bdfs.Bdfs\", \n",
    "        \"spark.hadoop.fs.AbstractFileSystem.dtap.impl\" : \"com.bluedata.hadoop.bdfs.BdAbstractFS\", \n",
    "        \"spark.hadoop.fs.dtap.impl.disable.cache\" : false, \n",
    "        \"spark.kubernetes.driver.label.hpecp.hpe.com/dtap\" : \"hadoop2\", \n",
    "        \"spark.kubernetes.executor.label.hpecp.hpe.com/dtap\" : \"hadoop2\", \n",
    "        \"spark.jars\" : \"local:///opt/bdfs/bluedata-dtap.jar\", \n",
    "        \"spark.kubernetes.container.image\" : \"devsds/spark-2.4.7:202104010902C\" \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7703ce-38ef-4a6a-9dc5-360447de3dbb",
   "metadata": {},
   "source": [
    "## Importing Libraries and Spark Configuration\n",
    "\n",
    "Don't forget to put in your intitials in the <b>STUDENT</b> variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6563dc-f771-414b-a003-ee7f6cadafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Importing pyspark libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "#Fill in initials here\n",
    "STUDENT = \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b962a6-0c6f-4418-849e-ceb008fc0cdb",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ebdf5-c00f-4042-ab18-9306532cbc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('dtap://TenantStorage/Scada-Dataset/T1.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5205727-659d-4042-a684-0a62014f6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching the dataset\n",
    "spark_df.cache()\n",
    "\n",
    "# Converting all the column names to lower case\n",
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])\n",
    "\n",
    "print('Show the first 5 rows')\n",
    "print(spark_df.show(5))\n",
    "print()\n",
    "print('What are the variable data types?')\n",
    "print(spark_df.printSchema())\n",
    "print()\n",
    "print('How many observations do we have?')\n",
    "print(spark_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c1440-108c-4c0d-a0b2-8eef645bbdb1",
   "metadata": {
    "papermill": {
     "duration": 0.642383,
     "end_time": "2020-11-06T11:51:10.124124",
     "exception": false,
     "start_time": "2020-11-06T11:51:09.481741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting a substring from columns to create month and hour variables\n",
    "\n",
    "from pyspark.sql.functions import substring\n",
    "spark_df = spark_df.withColumn(\"month\", substring(\"date/time\", 4,2))\n",
    "spark_df = spark_df.withColumn(\"hour\", substring(\"date/time\", 12,2))\n",
    "\n",
    "# Converting string month and hour variables to integer\n",
    "from pyspark.sql.types import IntegerType\n",
    "spark_df = spark_df.withColumn('month', spark_df.month.cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn('hour', spark_df.hour.cast(IntegerType()))\n",
    "\n",
    "print(spark_df.show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a0fe3-f547-410b-96c4-48f41c6e772b",
   "metadata": {
    "papermill": {
     "duration": 0.2121,
     "end_time": "2020-11-06T11:51:10.610005",
     "exception": false,
     "start_time": "2020-11-06T11:51:10.397905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9af005-2fa4-406a-916a-acf8a86e080f",
   "metadata": {
    "papermill": {
     "duration": 1.082073,
     "end_time": "2020-11-06T11:51:11.875479",
     "exception": false,
     "start_time": "2020-11-06T11:51:10.793406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "spark_df.select('wind speed (m/s)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)').toPandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b307c1-a390-439f-ba32-e7a0bdceea04",
   "metadata": {
    "papermill": {
     "duration": 0.18721,
     "end_time": "2020-11-06T11:51:12.251424",
     "exception": false,
     "start_time": "2020-11-06T11:51:12.064214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: What are the distributions of the variables?\n",
    "\n",
    "**For creating visualization we need to either use aggregated data or use a sample from the big data.**\n",
    "\n",
    "**So we will get a random sample from our input.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44f588-093a-4c52-9bae-ba47e13f3cab",
   "metadata": {
    "papermill": {
     "duration": 2.728132,
     "end_time": "2020-11-06T11:51:15.161751",
     "exception": false,
     "start_time": "2020-11-06T11:51:12.433619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Taking a random sample from the big data\n",
    "sample_df = spark_df.sample(withReplacement=False, fraction=0.1, seed=42).toPandas()\n",
    "\n",
    "# Visualizing the distributions with the sample data\n",
    "columns = ['wind speed (m/s)', 'wind direction (deg)', 'month', 'hour', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']\n",
    "i=1\n",
    "plt.figure(figsize=(10,12))\n",
    "for each in columns:\n",
    "    plt.subplot(3,2,i)\n",
    "    sample_df[each].plot.hist(bins=12)\n",
    "    plt.title(each)\n",
    "    i += 1\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9526fd39-0f69-49b6-8267-1f82a924fdf4",
   "metadata": {
    "papermill": {
     "duration": 0.205233,
     "end_time": "2020-11-06T11:51:15.559053",
     "exception": false,
     "start_time": "2020-11-06T11:51:15.353820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: Is there any difference between the months for average power production ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8905f4-57b0-4ba6-8e11-3a7a8b06522d",
   "metadata": {
    "papermill": {
     "duration": 6.882465,
     "end_time": "2020-11-06T11:51:22.627842",
     "exception": false,
     "start_time": "2020-11-06T11:51:15.745377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Average power production by month\n",
    "monthly = spark_df.groupby('month').mean('lv activepower (kw)').sort('avg(lv activepower (kw))').toPandas()\n",
    "sns.barplot(x='month', y='avg(lv activepower (kw))', data=monthly)\n",
    "plt.title('Months and Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bca08-4374-438f-82bb-c8d37c9c4f29",
   "metadata": {
    "papermill": {
     "duration": 0.19086,
     "end_time": "2020-11-06T11:51:23.011507",
     "exception": false,
     "start_time": "2020-11-06T11:51:22.820647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: Is there any difference between the hours for average power production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfcc048-0ca5-483f-bf27-3b8627bce428",
   "metadata": {
    "papermill": {
     "duration": 4.709979,
     "end_time": "2020-11-06T11:51:27.917131",
     "exception": false,
     "start_time": "2020-11-06T11:51:23.207152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Average power production by hour\n",
    "hourly = spark_df.groupby('hour').mean('lv activepower (kw)').sort('avg(lv activepower (kw))').toPandas()\n",
    "sns.barplot(x='hour', y='avg(lv activepower (kw))', data=hourly)\n",
    "plt.title('Hours and Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ab325-c9c1-4bea-9842-c0dcd405bec9",
   "metadata": {
    "papermill": {
     "duration": 0.189562,
     "end_time": "2020-11-06T11:51:28.303900",
     "exception": false,
     "start_time": "2020-11-06T11:51:28.114338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: Is there any correlation between the wind speed, wind direction and power production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb752d4-9832-4447-80c4-1ca1518e1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "sample_df[columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669b7c4-ada0-40c9-b459-17cdfe60b5f2",
   "metadata": {
    "papermill": {
     "duration": 12.41678,
     "end_time": "2020-11-06T11:51:40.905426",
     "exception": false,
     "start_time": "2020-11-06T11:51:28.488646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "sns.pairplot(sample_df[columns], markers='*');\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bcc24c-9c7f-4005-8432-87fa3c1d10b8",
   "metadata": {
    "papermill": {
     "duration": 0.212448,
     "end_time": "2020-11-06T11:51:41.333291",
     "exception": false,
     "start_time": "2020-11-06T11:51:41.120843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Wind speed and power production is highly correlated as one would expect.**\n",
    "\n",
    "**We can see there are lower level power production for some wind directions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec6915-db0b-4a45-a4ef-83da44304356",
   "metadata": {
    "papermill": {
     "duration": 0.212266,
     "end_time": "2020-11-06T11:51:41.754091",
     "exception": false,
     "start_time": "2020-11-06T11:51:41.541825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: What is the average power production level for different wind speeds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55138b8-acb4-491e-82bd-79915c81eec9",
   "metadata": {
    "papermill": {
     "duration": 1.574594,
     "end_time": "2020-11-06T11:51:43.537776",
     "exception": false,
     "start_time": "2020-11-06T11:51:41.963182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding average power production for 5 m/s wind speed increments\n",
    "wind_speed = []\n",
    "avg_power = []\n",
    "for i in [0,5,10,15,20]:\n",
    "    avg_value = spark_df.filter((spark_df['wind speed (m/s)'] > i) \n",
    "                                & (spark_df['wind speed (m/s)'] <= i+5))\\\n",
    "                                .agg({'lv activepower (kw)':'mean'}).collect()[0][0] \n",
    "    avg_power.append(avg_value)\n",
    "    wind_speed.append(str(i) + '-' + str(i+5))\n",
    "\n",
    "plt.clf()\n",
    "sns.barplot(x=wind_speed, y=avg_power, color='orange')\n",
    "plt.title('Avg Power Production for 5 m/s Wind Speed Increments')\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Average Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab4ba98-b493-4fb9-880a-3c2b90183ac6",
   "metadata": {
    "papermill": {
     "duration": 0.206415,
     "end_time": "2020-11-06T11:51:43.953617",
     "exception": false,
     "start_time": "2020-11-06T11:51:43.747202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**From the graph above we can see the power production reaches near a maximum level after the wind speed reaches 15 m/s.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43865a-daad-4403-bb5a-e5e4e5bb62a3",
   "metadata": {
    "papermill": {
     "duration": 0.209637,
     "end_time": "2020-11-06T11:51:44.374633",
     "exception": false,
     "start_time": "2020-11-06T11:51:44.164996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: What is the power production for different wind directions and speeds? \n",
    "\n",
    "**Let's create a polar diagram with wind speed, wind direction and power production from the sample data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43d1ad-ff0e-4d6b-8df6-e33bba1b1110",
   "metadata": {
    "papermill": {
     "duration": 0.637592,
     "end_time": "2020-11-06T11:51:45.220835",
     "exception": false,
     "start_time": "2020-11-06T11:51:44.583243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the polar diagram\n",
    "from math import radians\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "# Inside circles are the wind speed and marker color and size represents the amount of power production\n",
    "sns.scatterplot(x=[radians(x) for x in sample_df['wind direction (deg)']], \n",
    "                y=sample_df['wind speed (m/s)'],\n",
    "                size=sample_df['lv activepower (kw)'],\n",
    "                hue=sample_df['lv activepower (kw)'],\n",
    "                alpha=0.7, legend=None)\n",
    "# Setting the polar diagram's top represents the North \n",
    "ax.set_theta_zero_location('N')\n",
    "# Setting -1 to start the wind direction clockwise\n",
    "ax.set_theta_direction(-1)\n",
    "# Setting wind speed labels in a better position to see\n",
    "ax.set_rlabel_position(110)\n",
    "plt.title('Wind Speed - Wind Direction - Power Production Diagram')\n",
    "plt.ylabel(None);\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a26e25-645e-4e78-9041-6ab56b571b01",
   "metadata": {
    "papermill": {
     "duration": 0.214825,
     "end_time": "2020-11-06T11:51:45.657665",
     "exception": false,
     "start_time": "2020-11-06T11:51:45.442840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We can see that the wind turbine produces more power if the wind blows from the directions between 0-90 and 180-225 degrees.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0448cb1-c053-4e6a-a0de-cd9a7bb457dc",
   "metadata": {
    "papermill": {
     "duration": 0.217836,
     "end_time": "2020-11-06T11:51:46.089108",
     "exception": false,
     "start_time": "2020-11-06T11:51:45.871272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: Does the manufacturer's theoritical power production curve fit well with the real production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7bf28-7931-4c02-a7d8-a3e5e37c0f8b",
   "metadata": {
    "papermill": {
     "duration": 1.357292,
     "end_time": "2020-11-06T11:51:47.666115",
     "exception": false,
     "start_time": "2020-11-06T11:51:46.308823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='wind speed (m/s)', y='lv activepower (kw)', color='orange', label='Real Production', alpha=0.5, data=sample_df)\n",
    "sns.lineplot(x='wind speed (m/s)', y='theoretical_power_curve (kwh)', color='blue', label='Theoritical Production', data=sample_df)\n",
    "plt.title('Wind Speed and Power Production Chart')\n",
    "plt.ylabel('Power Production (kw)');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471834a7-55bb-4d94-b6cd-d300f2649061",
   "metadata": {
    "papermill": {
     "duration": 0.216557,
     "end_time": "2020-11-06T11:51:48.104186",
     "exception": false,
     "start_time": "2020-11-06T11:51:47.887629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**From the graph above, we can see the theoritical power production curve generally fits well with the real production.**\n",
    "\n",
    "**We can see the power production reaches a maximum level and continues in a straight line if the wind speed reaches to 15 m/s.**\n",
    "\n",
    "**Also we can see there are some 0 power production, even the wind speed is higher than 5 m/s. Lets investigate the reason.**\n",
    "\n",
    "**But before that what is the minimum wind speed for theoritical power production curve?**\n",
    "\n",
    "### Question: What is the wind speed threshold value for zero theorical power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e5241-6114-4ad7-a0b1-2e27dd8f2050",
   "metadata": {
    "papermill": {
     "duration": 0.876272,
     "end_time": "2020-11-06T11:51:49.198656",
     "exception": false,
     "start_time": "2020-11-06T11:51:48.322384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the big data where the real and theoritical power productions are equal to 0\n",
    "zero_theo_power = spark_df.filter((spark_df['lv activepower (kw)'] == 0)\n",
    "                                  & (spark_df['theoretical_power_curve (kwh)'] == 0)).toPandas()\n",
    "\n",
    "print(zero_theo_power[['wind speed (m/s)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a53abb-218f-4eed-87e2-d59ca85d1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# Let's see the wind speed distribution for 0 power production\n",
    "zero_theo_power['wind speed (m/s)'].hist()\n",
    "plt.title('Wind Speed Distribution for 0 Power Production')\n",
    "plt.xlabel('Wind speed (m/s)')\n",
    "plt.ylabel('Counts for 0 Power Production');\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72ee9c-78ba-4a3f-bff7-25a67b38857d",
   "metadata": {
    "papermill": {
     "duration": 0.217121,
     "end_time": "2020-11-06T11:51:49.635932",
     "exception": false,
     "start_time": "2020-11-06T11:51:49.418811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We can see from above, limit for the theoritical power curve is 3 m/s wind speed. If the wind speed is below 3 m/s model doesn't expect any power production.**\n",
    "\n",
    "**But there are some observations for 0 power production even the wind speed is more than 3 m/s.**\n",
    "\n",
    "### Question: Why there aren't any power production in some observations while the wind speed is higher than 3 m/s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbe82a-25c9-4385-91b4-9016e33ba370",
   "metadata": {
    "papermill": {
     "duration": 0.440175,
     "end_time": "2020-11-06T11:51:50.296711",
     "exception": false,
     "start_time": "2020-11-06T11:51:49.856536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Observations for the wind speed > 3m/s and power production = 0, \n",
    "# While theoritically there should be power production\n",
    "zero_power = spark_df.filter((spark_df['lv activepower (kw)'] == 0)\n",
    "                            & (spark_df['theoretical_power_curve (kwh)'] != 0)\n",
    "                            & (spark_df['wind speed (m/s)'] > 3)).toPandas()\n",
    "print(zero_power.head())\n",
    "print('No of Observations (while Wind Speed > 3 m/s and Power Production = 0): ', len(zero_power))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375f204-9d2b-4796-a6a3-4634b335cba3",
   "metadata": {
    "papermill": {
     "duration": 0.217107,
     "end_time": "2020-11-06T11:51:50.734365",
     "exception": false,
     "start_time": "2020-11-06T11:51:50.517258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**There are 3497 observations where theoritically there should be power production. From the dataset we cannot see the reason, it might be caused by maintenance. But let's see if we can see any information from the wind speed, direction and month?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebbd3d-ffb0-46e9-a17a-c7e2e6c91293",
   "metadata": {
    "papermill": {
     "duration": 0.49059,
     "end_time": "2020-11-06T11:51:51.468798",
     "exception": false,
     "start_time": "2020-11-06T11:51:50.978208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "zero_power['wind speed (m/s)'].plot.hist(bins=8)\n",
    "plt.xlabel('Wind Speed (m/s)')\n",
    "plt.ylabel('Counts for Zero Production')\n",
    "plt.title('Wind Speed Counts for Zero Power Production')\n",
    "plt.xticks(ticks=np.arange(4,18,2));\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1446f4-3718-4406-b713-577e22a48a86",
   "metadata": {
    "papermill": {
     "duration": 0.218898,
     "end_time": "2020-11-06T11:51:51.908248",
     "exception": false,
     "start_time": "2020-11-06T11:51:51.689350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**It looks like theoritically wind speed threshold should be 4 m/s. But there are also other observations with zero power production while the wind speed is higher.**\n",
    "\n",
    "**Let's see the monthly distribution for zero power production.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58649a-fae8-4a7d-bf1c-1a04eb11d551",
   "metadata": {
    "papermill": {
     "duration": 0.505913,
     "end_time": "2020-11-06T11:51:52.688247",
     "exception": false,
     "start_time": "2020-11-06T11:51:52.182334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "sns.countplot(zero_power['month']);\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a72a2f-9a13-4904-a57a-1d1e927b4c67",
   "metadata": {
    "papermill": {
     "duration": 0.22068,
     "end_time": "2020-11-06T11:51:53.128477",
     "exception": false,
     "start_time": "2020-11-06T11:51:52.907797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**It is usually in December and January when the wind turbine doesn't produce production.**\n",
    "\n",
    "**Because on the available information we cannot decide if these zero power productions are caused by maintenance periods or something else, Lets assume those 3497 observations as outliers and remove them from the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4dfc8-d288-4fbc-ad70-743fee75c198",
   "metadata": {
    "papermill": {
     "duration": 0.252337,
     "end_time": "2020-11-06T11:51:53.602583",
     "exception": false,
     "start_time": "2020-11-06T11:51:53.350246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Excluding the observations meeting the filter criterias \n",
    "spark_df = spark_df.filter(~((spark_df['lv activepower (kw)'] == 0)\n",
    "                            & (spark_df['theoretical_power_curve (kwh)'] != 0)\n",
    "                            & (spark_df['wind speed (m/s)'] > 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067f8e6-645f-46ce-bea7-6742ca309f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dffc10-595d-4bee-8f2d-c0cef3a93fee",
   "metadata": {
    "papermill": {
     "duration": 0.221357,
     "end_time": "2020-11-06T11:51:54.045923",
     "exception": false,
     "start_time": "2020-11-06T11:51:53.824566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: Is there any other outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f9079-720d-450a-a7fe-5fdb782d4883",
   "metadata": {
    "papermill": {
     "duration": 3.327251,
     "end_time": "2020-11-06T11:51:57.598007",
     "exception": false,
     "start_time": "2020-11-06T11:51:54.270756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['wind speed (m/s)', 'wind direction (deg)', 'theoretical_power_curve (kwh)', 'lv activepower (kw)']\n",
    "i=1\n",
    "plt.clf()\n",
    "plt.figure(figsize=(20,3))\n",
    "for each in columns:\n",
    "    df = spark_df.select(each).toPandas()\n",
    "    plt.subplot(1,4,i)\n",
    "    #plt.boxplot(df)\n",
    "    sns.boxplot(x=df[each])\n",
    "    plt.title(each)\n",
    "    i += 1\n",
    "    \n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9eaec4-045f-40b4-96af-7ed576feff0a",
   "metadata": {
    "papermill": {
     "duration": 0.242393,
     "end_time": "2020-11-06T11:51:58.072797",
     "exception": false,
     "start_time": "2020-11-06T11:51:57.830404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**From the graphs above we can see there are some outliers in the wind speed data.**\n",
    "\n",
    "**We will find the upper and lower threshold values for the wind speed data, and analyze the outliers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7251e9-cb3a-4e68-832b-516fd85c6e01",
   "metadata": {
    "papermill": {
     "duration": 0.657996,
     "end_time": "2020-11-06T11:51:58.959167",
     "exception": false,
     "start_time": "2020-11-06T11:51:58.301171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pandas df for visualization\n",
    "wind_speed = spark_df.select('wind speed (m/s)').toPandas()\n",
    "\n",
    "# Defining the quantiles and interquantile range\n",
    "Q1 = wind_speed['wind speed (m/s)'].quantile(0.25)\n",
    "Q3 = wind_speed['wind speed (m/s)'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "# Defining the lower and upper threshold values\n",
    "lower = Q1 - 1.5*IQR\n",
    "upper = Q3 + 1.5*IQR\n",
    "\n",
    "print('Quantile (0.25): ', Q1, '  Quantile (0.75): ', Q3)\n",
    "print('Lower threshold: ', lower, ' Upper threshold: ', upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce638704-d12f-4b7b-abb8-2b1d9d97c919",
   "metadata": {
    "papermill": {
     "duration": 0.240218,
     "end_time": "2020-11-06T11:51:59.424223",
     "exception": false,
     "start_time": "2020-11-06T11:51:59.184005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fancy indexing for outliers\n",
    "outlier_tf = (wind_speed['wind speed (m/s)'] < lower) | (wind_speed['wind speed (m/s)'] > upper)\n",
    "\n",
    "print('Total Number of Outliers: ', len(wind_speed['wind speed (m/s)'][outlier_tf]))\n",
    "print('--'*15)\n",
    "print('Some Examples of Outliers:')\n",
    "print(wind_speed['wind speed (m/s)'][outlier_tf].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3efb7-761a-4f09-b808-ebca1bc43134",
   "metadata": {
    "papermill": {
     "duration": 0.224447,
     "end_time": "2020-11-06T11:51:59.871244",
     "exception": false,
     "start_time": "2020-11-06T11:51:59.646797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**It is a rare event for wind speed to be over 19 m/s in our dataset.**\n",
    "\n",
    "**Out of 47033, there is only 407 observations while the wind speed is over 19 m/s.**\n",
    "\n",
    "**Now Lets see average power production for these high wind speed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea63219-e1b7-4b86-a7fa-1e50ce1eba18",
   "metadata": {
    "papermill": {
     "duration": 0.478202,
     "end_time": "2020-11-06T11:52:00.572495",
     "exception": false,
     "start_time": "2020-11-06T11:52:00.094293",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark_df.select('wind speed (m/s)', 'lv activepower (kw)')\\\n",
    ".filter(spark_df['wind speed (m/s)'] >= 19)\\\n",
    ".agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0c730-15bd-44e9-b444-ab8652f985ad",
   "metadata": {
    "papermill": {
     "duration": 0.227691,
     "end_time": "2020-11-06T11:52:01.033878",
     "exception": false,
     "start_time": "2020-11-06T11:52:00.806187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**So instead of erasing the outliers, we are going to set the wind speed as 19 m/s for those observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb27b8d-9269-44ca-a3f2-6a995e720d35",
   "metadata": {
    "papermill": {
     "duration": 0.450461,
     "end_time": "2020-11-06T11:52:01.716117",
     "exception": false,
     "start_time": "2020-11-06T11:52:01.265656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "spark_df = spark_df.withColumn('wind speed (m/s)', \n",
    "                               F.when(F.col('wind speed (m/s)') > 19.447, 19)\n",
    "                               .otherwise(F.col('wind speed (m/s)')))\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9eeaa-d8ec-4e0c-ba05-44a7c45b81a3",
   "metadata": {
    "papermill": {
     "duration": 0.227405,
     "end_time": "2020-11-06T11:52:02.198393",
     "exception": false,
     "start_time": "2020-11-06T11:52:01.970988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Question: What are the general criterias for power production?\n",
    "\n",
    "**It is important to understand the pattern in the data. We should learn the data before the machine.**\n",
    "\n",
    "**1. We saw from the graph that in March, August and November, the average power production is higher.**\n",
    "\n",
    "**2. The average power production is higher daily between 16:00 and 24:00.**\n",
    "\n",
    "**3. The power production is higher when the wind blows from the directions between 0-90 and 180-225 degrees.**\n",
    "\n",
    "**So let's try to predict a high and low level of power production from the criterias above before ML algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034c7f5-9eba-43c4-ba68-54d7c1a8b51f",
   "metadata": {
    "papermill": {
     "duration": 0.692232,
     "end_time": "2020-11-06T11:52:03.114446",
     "exception": false,
     "start_time": "2020-11-06T11:52:02.422214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# High level power production\n",
    "spark_df.filter(((spark_df['month'] == 3) | (spark_df['month'] == 8) | (spark_df['month'] == 11)) \n",
    "                & ((spark_df['hour'] >= 16) | (spark_df['hour'] <= 24)) \n",
    "                & ((spark_df['wind direction (deg)'] > 0) | (spark_df['wind direction (deg)'] < 90))\n",
    "                & ((spark_df['wind direction (deg)'] > 180) | (spark_df['wind direction (deg)'] < 225))\n",
    "               ).agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466fb5e-62cb-4a57-8038-0a3e52fc3882",
   "metadata": {
    "papermill": {
     "duration": 0.625395,
     "end_time": "2020-11-06T11:52:03.968868",
     "exception": false,
     "start_time": "2020-11-06T11:52:03.343473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Low level power production\n",
    "spark_df.filter((spark_df['month'] == 7) \n",
    "                & ((spark_df['hour'] >= 9) | (spark_df['hour'] <= 11)) \n",
    "                & ((spark_df['wind direction (deg)'] > 90) | (spark_df['wind direction (deg)'] < 160))\n",
    "               ).agg({'lv activepower (kw)':'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d32c0-4eb0-4fe6-8f48-8d8a70ece896",
   "metadata": {
    "papermill": {
     "duration": 0.231145,
     "end_time": "2020-11-06T11:52:04.438338",
     "exception": false,
     "start_time": "2020-11-06T11:52:04.207193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation for ML Algorithms\n",
    "\n",
    "**After analysing and understanding the dataset, we can build a ML regression model to predict wind turbine power production by using the wind speed, wind direction, month of the year and hour of the day.**\n",
    "\n",
    "**Using ML algorithms with Spark is a bit different from well known Sckitlearn library.**\n",
    "\n",
    "**We need to feed the model with a dataframe made of variables compressed in vectors called as 'features', and target variable as 'label'. For these convertions we are going to use VectorAssembler method from Pyspark.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d495b6e-7128-4f7f-85c0-8f4fa05392a8",
   "metadata": {
    "papermill": {
     "duration": 0.80181,
     "end_time": "2020-11-06T11:52:05.468136",
     "exception": false,
     "start_time": "2020-11-06T11:52:04.666326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the independent variables (Features)\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Converting lv activepower (kw) variable as label\n",
    "spark_df = spark_df.withColumn('label', spark_df['lv activepower (kw)'])\n",
    "\n",
    "# Defining the variables to be used\n",
    "variables = ['month', 'hour', 'wind speed (m/s)', 'wind direction (deg)']\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "va_df = vectorAssembler.transform(spark_df)\n",
    "\n",
    "# Combining features and label column\n",
    "final_df = va_df.select('features', 'label')\n",
    "final_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab0e11-d3df-4c60-8a63-fc0aa02235a9",
   "metadata": {
    "papermill": {
     "duration": 0.228307,
     "end_time": "2020-11-06T11:52:05.925155",
     "exception": false,
     "start_time": "2020-11-06T11:52:05.696848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Test Split\n",
    "\n",
    "**Now we can split our dataset into train and test datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9d8f4-0e74-42a7-80f5-d40b0557cc6a",
   "metadata": {
    "papermill": {
     "duration": 1.993646,
     "end_time": "2020-11-06T11:52:08.152397",
     "exception": false,
     "start_time": "2020-11-06T11:52:06.158751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = final_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "train_df.write.save(\"dtap://TenantStorage/Scada-Dataset/\" + STUDENT + \"_train_df.parquet\")\n",
    "test_df.write.save(\"dtap://TenantStorage/Scada-Dataset/\" + STUDENT + \"_test_df.parquet\")\n",
    "\n",
    "print('Train dataset: ', train_df.count())\n",
    "print('Test dataset : ', test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6aeba4-5bbc-4edd-be87-07f98f214be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('dtap://TenantStorage/Scada-Dataset/T1.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Caching the dataset\n",
    "spark_df.cache()\n",
    "\n",
    "# Converting all the column names to lower case\n",
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])\n",
    "\n",
    "# Extracting a substring from columns to create month and hour variables\n",
    "\n",
    "from pyspark.sql.functions import substring\n",
    "spark_df = spark_df.withColumn(\"month\", substring(\"date/time\", 4,2))\n",
    "spark_df = spark_df.withColumn(\"hour\", substring(\"date/time\", 12,2))\n",
    "\n",
    "# Converting string month and hour variables to integer\n",
    "from pyspark.sql.types import IntegerType\n",
    "spark_df = spark_df.withColumn('month', spark_df.month.cast(IntegerType()))\n",
    "spark_df = spark_df.withColumn('hour', spark_df.hour.cast(IntegerType()))\n",
    "\n",
    "# Taking a random sample from the big data\n",
    "sample_df = spark_df.sample(withReplacement=False, fraction=0.1, seed=42).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40b7f2-2864-4c25-afe9-1a9940babf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spark.read.load('dtap://TenantStorage/Scada-Dataset/' + STUDENT + '_train_df.parquet')\n",
    "test_df = spark.read.load('dtap://TenantStorage/Scada-Dataset/' + STUDENT + '_test_df.parquet')\n",
    "\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7761a-81bb-439f-8e35-3ae2db61abee",
   "metadata": {},
   "source": [
    "## Creating the Initial Model\n",
    "\n",
    "**Lets use GBT regressor for this study.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18fa94-b0be-48b4-8b03-24d8129f3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Creating the gbm regressor object\n",
    "gbm = GBTRegressor(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Training the model with train data\n",
    "gbm_model = gbm.fit(train_df)\n",
    "\n",
    "# Predicting using the test data\n",
    "y_pred = gbm_model.transform(test_df)\n",
    "\n",
    "# Initial look at the target and predicted values\n",
    "y_pred.select('label', 'prediction').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b41356-638a-4ea0-a4be-ff0382e0c803",
   "metadata": {},
   "source": [
    "**Store our model in dtap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7ee2f-1ea7-44a7-92ff-fe9f7e7c7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model.save('dtap://TenantStorage/Scada-Model/' + STUDENT + '_GBM.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9edc085-7a24-4e6e-a17c-ba2cc23f7824",
   "metadata": {},
   "source": [
    "**Load Model - Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72dfa8-5618-4971-9254-02b76bbad618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "gbm_model_dtap = GBTRegressionModel.load(\"dtap://TenantStorage/Scada-Model/\" + STUDENT + \"_GBM.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3628ae2-ce92-485d-9eb6-b2b35dc071b4",
   "metadata": {},
   "source": [
    "**Let's evaluate our model's success.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac4dc7-22d7-4c45-b92b-7d44995d8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model success\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "\n",
    "print('R2 SCORE : ', evaluator.evaluate(y_pred, {evaluator.metricName: 'r2'}))\n",
    "print('MAE      : ', evaluator.evaluate(y_pred, {evaluator.metricName: 'mae'}))\n",
    "print('RMSE     : ', evaluator.evaluate(y_pred, {evaluator.metricName: 'rmse'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda465c9-f4db-487c-9321-a074b387cd3d",
   "metadata": {},
   "source": [
    "**R2 score means, real power production's 98% variability can be explained by the ML model.**\n",
    "\n",
    "**MAE is the mean absolute difference between the real and predicted power production.**\n",
    "\n",
    "**RMSE is the square root of mean squared difference between the real and predicted values.**\n",
    "\n",
    "**Even though the R2 is high, we should also check the MAE and RMSE values with the real value's summary statistics.**\n",
    "\n",
    "**One can tune the hyperparameters to increase the model success.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cd363-267c-4a70-8d2e-399cdc5ba4cf",
   "metadata": {},
   "source": [
    "## Comparing Real, Theoritical and Predicted Power Productions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b60377-33a8-4285-ad80-deb5e73676e4",
   "metadata": {},
   "source": [
    "**Lets use sample_df for comparing the actual, theoritical and the model power productions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22466f3-ef5c-4f4b-a847-eb2ce3d5a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Converting sample_df back to Spark dataframe\n",
    "eva_df = spark.createDataFrame(sample_df)\n",
    "\n",
    "# Converting lv activepower (kw) variable as label\n",
    "eva_df = eva_df.withColumn('label', eva_df['lv activepower (kw)'])\n",
    "\n",
    "# Defining the variables to be used\n",
    "variables = ['month', 'hour', 'wind speed (m/s)', 'wind direction (deg)']\n",
    "vectorAssembler = VectorAssembler(inputCols = variables, outputCol = 'features')\n",
    "vec_df = vectorAssembler.transform(eva_df)\n",
    "\n",
    "# Combining features and label column\n",
    "vec_df = vec_df.select('features', 'label')\n",
    "\n",
    "# Using ML model to predict\n",
    "preds = gbm_model.transform(vec_df)\n",
    "preds_df = preds.select('label','prediction').toPandas()\n",
    "\n",
    "# Compining dataframes to compare\n",
    "frames = [sample_df[['wind speed (m/s)', 'theoretical_power_curve (kwh)']], preds_df]\n",
    "sample_data = pd.concat(frames, axis=1)\n",
    "\n",
    "plt.clf()\n",
    "# Visualizing real, theoritical and predicted power production\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x='wind speed (m/s)', y='label',alpha=0.5, label= 'Real Power', data=sample_data)\n",
    "sns.scatterplot(x='wind speed (m/s)', y='prediction', alpha=0.7, label='Predicted Power', marker='o', data=sample_data)\n",
    "sns.lineplot(x='wind speed (m/s)', y='theoretical_power_curve (kwh)', label='Theoritical Power',color='purple', data=sample_data)\n",
    "plt.title('Wind Turbine Power Production Prediction')\n",
    "plt.ylabel('Power Production (kw)')\n",
    "plt.legend();\n",
    "\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc05c9-e754-4b88-8b63-5cce00c688af",
   "metadata": {},
   "source": [
    "**From the graph above, the model fits better to the real power productions, than the theoritical power production curve.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
